\subsection{Objekterkennung}
\label{sec_objDet}
In diesem Kapitel wird die umgesetzte Objekterkennung beschrieben. Dabei wird aus einem Rohbild der Kamera ein \textit{pointInFrame}-Objekt erzeugt. Grob besteht die Objekterkennung aus zwei Schritten. Zuerst wird aus dem Rohbild ein Binärbild erzeugt und im Anschluss im Binärbild das gesuchte Objekt detektiert.
\subsubsection{Binärbild mit Template}
\label{sec_templ}
\todo{Kann man die graphen mit legends gut genug erkennen?}
Die Objekterkennung basiert auf einem ähnlichen Verfahren wie das vorgestellte CSurvey Projekt\cite{Albiez2015CSurveyA}.\\
Da eine Farberkennung aufgrund der Sichtbedingungen nicht in Frage kommt, wird im ersten Schritt das RGB-Bild in ein Graustufenbild umgewandelt. Der erste Ansatz bestand darin, das Helligkeitsbild zu betrachten, da ein gesuchtes Objekt einen höheren Helligkeitswert besitzt als der Meeresboden (siehe Abb. \ref{brightCurve_real} und \ref{brightCurve_sim}).\\
Aus Erfahrungswerten früherer Projekte riet Christopher Gaudig mir, die Rotwerte der Bilder zu betrachten, da oftmals sowohl der Meeresboden als auch trübes Wasser geringe Rotwerte haben. In den Abbildungen \ref{redCurve_real} und \ref{redCurve_sim} ist dies zu beobachten. Die Kurven sehen denen der Helligkeitswerte sehr ähnlich, jedoch sind die Ausschläge des Objektes in den Rotwerten höher.\\
Im nächsten Schritt wird mithilfe eines Templates [Abb. \ref{templImg}] ein Binärbild erzeugt. Das Template zeichnet sich durch drei Pixelangaben aus. Die \textit{Testpixel} (rot) geben einen Bereich an, der im aktuellen Schritt geprüft wird. Die \textit{Checkpixel} (blau) geben den Bereich rechts und links neben dem Testbereich an und bilden den Referenzwert. Die \textit{Borderpixel} (grün) geben einen Bereich zwischen Test- und Checkbereich an, der ignoriert wird. Durch das Ignorieren des Bereichs kann ein langsamer regelmäßiger Übergang, der bei Betrachtung der direkten Nachbarpixeln des Testbereichs als Checkbereich zu einem geringen Templatewert führt, trotzdem noch einen hohen Templatewert ergeben. Jedes Pixel dient einmal als Mittelpunkt des Testbereichs, um zu entscheiden, ob das betrachtete Pixel Teil des Objektes sein kann. Dies ist der Fall, wenn der Wert des Pixels [Gleichung \ref{templateValue}] einen Schwellenwert (rote Linie) übersteigt.\\
%\begin{ownequation}[H]
%\begin{eqnarray}
%TP_i = \left\{i-\frac{\#TP}{2} \dots i \dots i+\frac{\#TP}{2}\right\}\\
%LC_i = \left\{i-\frac{\#TP}{2}-\#BP-\#CP \dots i-\frac{\#TP}{2}-\#BP\right\}\\
%RC_i = \left\{i-i+\frac{\#TP}{2}+\#BP \dots \frac{\#TP}{2}+\#BP+\#CP\right\}\\
%\end{eqnarray}
%\caption{Testbereich ($TP$) und Checkbereiche ($LC$ und $RC$) für ein Pixel mit Index $i$}
%\end{ownequation}
%Mit diesen Mengen lässt sich dann die Berechnung eines Templatewerts ($TV$) zu definieren.
%\begin{ownequation}[H]
%\begin{eqnarray}
%TV_i = \frac{\sum_{x \in TP_i} image(x))}{\#TP} - \left(\frac{\sum_{y_1 \in LC_i} image(y_1) + \sum_{y_2 \in RC_i} image(y_2)}{2 \cdot \#CP}\right)
%\end{eqnarray}
%\caption{Templatewertberechnung für ein Pixel $i$}
%\label{templateValue}
%\end{ownequation}

\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{imageProcessing/Prinzip/template.jpg}
\caption[Template zum Bestimmen des Binärbilds]{Template zum Bestimmen des Binärbilds. Getestet wird das Pixel im Zentrum des Testbereichs (rot). Der Templatewert ergibt sich aus der Subtraktion des Durchschnitts im Checkbereich (blau) vom Durchschnitt des Testbereichs (rot). Der Borderbereich (grün) wird dabei nicht beachtet.}
\label{templImg}
\end{figure}

\begin{ownequation}[H]
\begin{equation}
TV = \frac{sum(Testpixel)}{\#TP} - \frac{sum(Checkpixel)}{\#CP}
\end{equation}
\caption[Templatewertberechnung für ein Pixel als Formelausdruck]{Templatewertberechnung für ein Pixel als Formelausdruck.Der berechnete Wert $TV$ ist der Unterschied zwischen Test- und Checkbereich.$\#TP$ bezeichnet die Anzahl der Testpixel und $\#CP$ die Anzahl der Checkpixel.}
\label{templateValue}
\end{ownequation}

\begin{figure}[H]
\begin{tabular}{cc}
\multicolumn{2}{c}{\subfloat[Originalbild. Das Testbild stammt aus Aufnahmen eines Testlaufs im Unisee (siehe Abschnitt \ref{realObjTests}.]{\includegraphics[height=0.33\textheight,width=\textwidth]{imageProcessing/realPipe/003orgImstart.jpg}}}\\
\subfloat[Auswertung des Helligkeitsverlauf einer Bildzeile im oberen Drittel des Bildes]{\includegraphics[height=0.33\textheight,width=0.5\textwidth]{imageProcessing/Prinzip/hellReal.jpg}\label{brightCurve_real}}&
\subfloat[Auswertung des Rotwertverlauf einer Bildzeile im oberen Drittel des Bildes]{\includegraphics[height=0.33\textheight,width=0.5\textwidth]{imageProcessing/Prinzip/rotReal.jpg}\label{redCurve_real}}
\end{tabular}
\caption[Helligkeit und Rotwert im echten Testbild]{Helligkeit und Rotwert im echten Testbild. In beiden Grafiken zeigt die blaue Linie die jeweiligen Pixeldaten, die gelbe Linie den Wert des Testbereichs, die lila Linie den Durchschnitt des Checkbereichs und die weiter unten gelegene rote Linie den Templatewert für das Pixel. In beiden Templatewerten ist die Pipeline eindeutig zu erkennen, wobei der Ausschlag im Rotwert weitaus höher ist.}
\end{figure}

\begin{figure}[H]
\begin{tabular}{cc}
\multicolumn{2}{c}{\subfloat[Originalbild der Simulation]{\includegraphics[height=0.33\textheight,width=0.4\textwidth]{imageProcessing/gradeTestQuali.jpg}}}\\
\subfloat[Auswertung des Helligkeitsverlaufs einer Bildzeile im oberen Drittel des Bildes]{\includegraphics[height=0.33\textheight,width=0.5\textwidth]{imageProcessing/Prinzip/hellSim.jpg}\label{brightCurve_sim}}&
\subfloat[Auswertung des Rotwertverlaufs einer Bildzeile im oberen Drittel des Bildes]{\includegraphics[height=0.33\textheight,width=0.5\textwidth]{imageProcessing/Prinzip/rotSim.jpg}\label{redCurve_sim}}
\end{tabular}
\caption[Helligkeit und Rotwert im Simulationsbild]{Helligkeit und Rotwert im Simulationsbild.In beiden Grafiken zeigt die blaue Linie die jeweiligen Pixeldaten, die gelbe Linie den Wert des Testbereichs, die lila Linie den Durchschnitt des Checkbereichs und die weiter unten gelegene rote Linie den Templatewert für das Pixel. In beiden Templatewerten ist die Pipeline eindeutig zu erkennen, wobei der Ausschlag im Rotwert weitaus höher ist.}
\end{figure}
\todo{neu machen}

\subsubsection{\rans auf Binärbild}
Im weiteren Verlauf wird auf dem  Binärbild gearbeitet. Nach dem Vorbild von Wang et al. \cite{wang2004lane} wird das Bild in drei Segmente unterteilt.\\
In jedem Segment wird dann mithilfe des \rans -Algorithmus ein Rechteck gesucht [Listing \ref{ransPseudo}]. Der Algorithmus sampled verschiedene Rechtecke im Segment. Jedes Rechteck wird durch einen Mittelpunkt, eine Orientierung, die Breite und die Höhe definiert. Die Höhe ergibt sich aus der Höhe des Segmentes und die Breite wird durch die erwartete Breite des Objektes festgelegt. Mittelpunkt und Orientierung werden in jedem Iterationsschritt zufällig gewählt.\\
Für jeden Punkt des Binärbilds wird dann geprüft, ob er im Rechteck liegt (ein \textit{Inlier} ist). Gemäß des \rans wird das Rechteck mit den meisten Inliern gewählt.\\
\begin{lstlisting}[language=Matlab,caption={Eingesetzter \rans als Pseudocode.},label=ransPseudo]
function ransac(segment,height,width,minInlier,iterNum)
	maxInlier = 0;
	orientations = -pi/4:0.05:pi/4;
	bestCenter = None;
	bestOrientation = None;
	for i = 1:iterNum
		boxCenter = selectRandomPoint(segment);
		boxOrientation = selectRandomValue(orientations);
		inliers = findPointsInBox(segment, box=[boxCenter,boxOrientation,height,width]);
		
		if(len(inliers) > minInlier && len(inliers) > maxInlier)
			maxInlier = len(inliers)
			bestCenter = boxCenter;
			bestOrientation = boxOrientation;
		end
	end
end
\end{lstlisting}

Somit gibt es für jedes Bild bis zu drei Objektposen. Durch das Unterteilen in Segmente lässt sich zum einen bestimmen, in wie vielen Segmenten ein Objekt erkannt wurde (entspricht der \textit{Länge} des Objektes im Bild). Des weiteren kann ein gebogener Verlauf oder ein abgeknicktes Objekt im Bild sinnvoll erkannt werden.\\
In den ersten Tests dieses Verfahrens ist ersichtlich geworden, dass es einen \todo{richtige wortwahl?}Tradeoff zwischen Geschwindigkeit und Erkennungsgüte gab. Die Erkennung wurde besser, je größer das Maximum der Iteration für \rans gewählt wurden. Da der \rans jedoch auf jedes der drei Segmente separat angewendet wird, reduziert sich die Geschwindigkeit bei steigender Iterationsanzahl deutlich. Für eine zuverlässige Erkennung waren zu viele Iterationen nötig, sodass das Verfahren nicht einsetzbar wäre.\\
Als Lösung für dieses Probleme werden die möglichen erzeugten Rechtecke für den \rans begrenzt. Da das Template nur in horizontaler Richtung auf das Bild angewendet wird, sind horizontal liegende Objekte im Binärbild nicht sichtbar. Aufgrund dieser Tatsache lassen sich die Orientierungen auf einen Bereich begrenzen, anstatt diese komplett zufällig zu wählen. Durch diese Maßnahme wurden die benötigten Iterationen für ein zuverlässiges Ergebnis drastisch reduziert. Jedoch steigt auch die Gefahr Orientierungen nicht mehr richtig zu erkennen, wie in Abbildung \ref{detecFail} gezeigt.\\
\begin{figure}[H]
\centering
\includegraphics[scale=0.5]{imageProcessing/realPipe/004detectedImage.jpg}
\caption{Falsch detektierte Objektorientierung aufgrund der Beschränkung der Ausrichtungen für den \rans}
\label{detecFail}
\end{figure}
\todo{evtl box vom ransac zeigen}
Der zweite Faktor, der die Geschwindigkeit der Objekterkennung verringerte, ist die Menge der Punkte im Binärbild. So musste für jede Iteration des \rans für jeden Punkt geprüft werden, ob der Punkt im Rechteck liegt. In den Testbildern der Simulation lag die Anzahl der Punkte teilweise bei weit über $10000$, was in Kombination mit $200$ Iterationen zu einer inakzeptablen Laufzeit von ca. 5 Sekunden pro Bild führte.\\
Zum Lösen dieses Problems wurde vor dem Einsatz des \rans die Punktanzahl verringert, indem nur jedes dritte Pixel betrachtet wird und dieses den Mittelwert aller seiner Nachbarpixel erhält. \todo{Grafik?} Somit konnte die Punktanzahl zuverlässig auf unter $2000$ verringert werden, was zu einer deutlichen Beschleunigung (ca. 1 Sekunde pro Bild) ohne nennenswerte Verschlechterung der Ergebnisse führte.
%\subsubsection*{Gewicht der erkannten Punkte}
%\label{sec_weights}
%\begin{itemize}
%\item \textbf{numParts:} Länge des Objektes im Bild. Die erkannten Punkte werden nach Parallelität ihrer Ausrichtung und Nähe zueinander untersucht. Somit wird untersucht in wievielen Segmenten das Objekt fortgeführt wird.
%\item \textbf{area:} Um den Punkt wird ein Rechteck gelegt, dass der Breite des Objektes und der Höhe des Segmentes entspricht. \textbf{area} gibt einen relativen Wert an, wie ausgefüllt dieses Rechteck ist.
%\item \textbf{peakheight:} Es wird der Mittelwert aller der Helligkeit innerhalb des Rechtecks berechnet und mit dem allgemeinen Helligkeitswert des Bildes verglichen. \textbf{peakheight} dieses Verhältnis relativ an.
%\item \textbf{fitsBorder:} Gibt als boolean an, ob das erkannte Objekt der berechneten Objektbreite passt.
%\item \textbf{relativeCount:} Gibt das Verhältnis von Punkten im Binärbild, die zum Objekt passen und der Gesamtzahl der Punkte an.
%\end{itemize}